{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ham',\n",
       "        'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       "        nan, nan, nan],\n",
       "       ['ham', 'Ok lar... Joking wif u oni...', nan, nan, nan],\n",
       "       ['spam',\n",
       "        \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       "        nan, nan, nan],\n",
       "       ...,\n",
       "       ['ham',\n",
       "        'Pity, * was in mood for that. So...any other suggestions?', nan,\n",
       "        nan, nan],\n",
       "       ['ham',\n",
       "        \"The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free\",\n",
       "        nan, nan, nan],\n",
       "       ['ham', 'Rofl. Its true to its name', nan, nan, nan]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 1]\n",
    "y = data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572,), (5572,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "sw = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStem(review):\n",
    "    review = review.lower()\n",
    "    tokens = tokenizer.tokenize(review) # breaking into small words\n",
    "    removed_stopwords = [w for w in tokens if w not in sw]\n",
    "    stemmed_words = [ps.stem(token) for token in removed_stopwords]\n",
    "    clean_review = ' '.join(stemmed_words)\n",
    "    return clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a clean document\n",
    "def getDoc(document):\n",
    "    d = []\n",
    "    for doc in document:\n",
    "        d.append(getStem(doc))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_doc = getDoc(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazi avail bugi n great world la e buffet cine got amor wat',\n",
       " 'ok lar joke wif u oni',\n",
       " 'free entri 2 wkli comp win fa cup final tkt 21st may 2005 text fa 87121 receiv entri question std txt rate c appli 08452810075over18',\n",
       " 'u dun say earli hor u c alreadi say',\n",
       " 'nah think goe usf live around though',\n",
       " 'freemsg hey darl 3 week word back like fun still tb ok xxx std chg send å 1 50 rcv',\n",
       " 'even brother like speak treat like aid patent',\n",
       " 'per request mell mell oru minnaminungint nurungu vettam set callertun caller press 9 copi friend callertun',\n",
       " 'winner valu network custom select receivea å 900 prize reward claim call 09061701461 claim code kl341 valid 12 hour',\n",
       " 'mobil 11 month u r entitl updat latest colour mobil camera free call mobil updat co free 08002986030']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_doc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create my vocab\n",
    "vc = cv.fit_transform(stemmed_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vc.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.977705274605764"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    \"\"\"\n",
    "        Dear All,\n",
    "        On the occasion of Raksha Bandhan, there will be no classes on Monday, 03 August 2020.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "       Join us today at 12:00 PM ET / 16:00 UTC for a Red Hat DevNation tech talk on AWS Lambda and serverless Java with Bill Burke.\n",
    "Have you ever tried Java on AWS Lambda but found that the cold-start latency and memory usage were far too high? \n",
    "In this session, we will show how we optimized Java for serverless applications by leveraging GraalVM with Quarkus to \n",
    "provide both supersonic startup speed and a subatomic memory footprint.\n",
    "        \n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "        Within the past few months, we have onboarded 100+ tech colleges and more than 12000+ students pan India.\n",
    "        Our Campus ambassadors help us build and lead these communities on their campuses and you can apply for this role too.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(messages):\n",
    "    d = getDoc(messages)\n",
    "    # dont do fit_transform!! it will create new vocab.\n",
    "    return cv.transform(d)\n",
    "\n",
    "messages = prepare(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(messages)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
